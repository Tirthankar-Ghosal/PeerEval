{"title": "ICLR 2018 Conference Acceptance Decision", "comment": "This paper studies the problem of synthesizing adversarial examples that will succeed at fooling a classification system under unknown viewpoint, lighting, etc conditions. For that purpose, the authors propose a data-augmentation technique (called \"EOT\") that makes adversarial examples robust against a predetermined family of transformations.\n\nReviewers were mixed in their assessment of this work, on the one hand highlighting the potential practical applications, but on the other hand warning about weak comparisons with existing literature, as well as lack of discussion about how to improve the robustness of the deep neural net against that form of attacks.\nThe AC thus believes this paper will greatly benefit from a further round of iteration/review, and therefore recommends rejection at this time. ", "decision": "Reject"}