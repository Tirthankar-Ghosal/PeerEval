{"title": "ICLR 2018 Conference Acceptance Decision", "comment": "meta score: 4\n\nThis paper proposes an activation function, called displaced ReLU (DReLU), to improve the performance of CNNs that use batch normalization.\n\nPros\n - good set of experiments using CIFAR, with good results\n - attempt to explain the approach using expectations\nCons\n - theoretical explanations are not so convincing\n - limited novelty\n - CIFAR is relatively limited set of experiments\n - does not compare with using bn after relu, which is now well-studied and seems to address the motivation of this paper (and thus questions the conclusions)", "decision": "Reject"}