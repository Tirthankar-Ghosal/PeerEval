{"title": "ICLR 2018 Conference Acceptance Decision", "comment": "First off, this was a difficult paper to decide on. There was some vigorous discussion on the paper centering around the choices that were available to the conv-nets.  The author's strongly emphasized the improvements on the PTB task.\n\nFor my part, I think the method is very compelling -- sharing weights for all the models we are optimizing on seems like a great idea -- and that we can make it work is even more interesting. So from this point of view, I think its a novel contribution and worth accepting.\n\nOn the other hand, I'm likely to agree with some of the motivations behind the questions raised by R3. Are all the choices really necessary ? perhaps the gains came from just a couple of things like number of skip connections and channels, etc. That exploration is useful. On the flip side, I think it may be an irrelevant question -- the model is able to make the correct decisions from a big set.\n\nThe authors emphasize the language modelling part, but for me, this was actually less compelling. The authors use some of the tricks from Merity in their model training (perplexity 52.8), and as a result are already using some techniques that produces better results. Further, PTB is a regularization game -- and that's not really the claim of this paper. Although, one could argue that weight sharing between different models can produce an ensembling / regularization effect and those gains may show up on PTB. A much more compelling story would have been to show that this method works on a large dataset where the impact of the architecture cannot be conflated with controlling overfitting better.\n\nAs a result, this puts the paper on the fence for me; even though I very much like the idea. Polishing the paper and making a more convincing case for both the CNNs and RNNs will make this paper a solid contribution in the future.", "decision": "Invite to Workshop Track"}