"In this paper active learning meets a challenging multitask domain: reinforcement learning in diverse Atari 2600 games.[[INT-NEU], [null], [SMY], [GEN]] A state of the art deep reinforcement learning algorithm (A3C) is used together with three active learning strategies to master multitask problem sets of increasing size, far beyond previously reported works.[[RWK-NEU,MET-NEU], [null], [SMY], [GEN]]\n\nAlthough the choice of problem domain is particular to Atari and reinforcement learning, the empirical observations, especially the difficulty of learning many different policies together, go far beyond the problem instantiations in this paper.[[EXP-NEU,ANA-NEU], [EMP-NEU], [DIS], [MAJ]] Naive multitask learning with deep neural networks fails in many practical cases, as covered in the paper.[[RWK-NEU], [CMP-NEG], [SMY], [GEN]] The one concern I have is perhaps the choice of distinct of Atari games to multitask learn may be almost adversarial, since naive multitask learning struggles in this case; but in practice, the observed interference can appear even with less visually diverse inputs.[[RWK-NEU,DAT-NEU,MET-NEU], [EMP-NEU], [DIS], [MAJ]]\n\nAlthough performance is still reduced compared to single task learning in some cases, this paper delivers an important reference point for future work towards achieving generalist agents, which master diverse tasks and represent complementary behaviours compactly at scale.[[MET-POS,RES-NEU,FWK-POS], [EMP-POS], [APC], [MAJ]]\n\nI wonder how efficient the approach would be on DM lab tasks, which have much more similar visual inputs, but optimal behaviours are still distinct.[[RWK-NEU,MET-NEU], [CMP-NEU,EMP-NEU], [DIS], [MAJ]]\n"