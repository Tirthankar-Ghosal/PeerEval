"This paper describes an approach to decode non-autoregressively for neural machine translation (and other tasks that can be solved via seq2seq models).[[INT-NEU], [null], [SMY], [GEN]] The advantage is the possibility of more parallel decoding which can result in a significant speed-up (up to a factor of 16 in the experiments described).[[MET-POS,RES-POS], [EMP-POS], [APC], [MAJ]] The disadvantage is that it is more complicated than a standard beam search as auto-regressive teacher models are needed for training and the results do not reach (yet) the same BLEU scores as standard beam search. [[RWK-NEU,MET-NEG,RES-NEG], [CMP-NEG,EMP-NEG], [CRT], [MAJ]]\n\nOverall, this is an interesting paper. [[OAL-POS], [null], [APC], [MAJ]]It would have been good to see a speed-accuracy curve which plots decoding speed for different sized models versus the achieved BLUE score on one of the standard benchmarks (like WMT14 en-fr or en-de) to understand better the pros and cons of the proposed approach and to be able to compare models at the same speed or the same BLEU scores.[[RWK-NEU,MET-NEU,RES-NEU,ANA-NEU,TNF-NEU], [CMP-NEU,PNF-NEU], [SUG], [MAJ]] Table 1 gives a hint of that but it is not clear whether much smaller models with standard beam search are possibly as good and fast as NAT -- losing 2-5 BLEU points on WMT14 is significant.[[RWK-NEU,MET-NEU,RES-NEU,TNF-NEU], [CMP-NEU,EMP-NEG], [DIS], [MAJ]]  While the Ro->En results are good, this particular language pair has not been used much by others;[[RWK-NEU,MET-NEU,RES-POS], [CMP-NEU], [APC], [MAJ]] it would have been more interesting to stay with a single well-used language pair and benchmark and analyze why WMT14 en->de and de->en are not improving more.[[MET-POS,ANA-NEU], [CMP-NEU,EMP-POS], [DIS], [MAJ]] Finally it would have been good to address total computation in the comparison as well -- it seems while total decoding time is smaller total computation for NAT + NPD is actually higher depending on the choice of s.[[EXP-NEU,RES-NEU,ANA-NEU], [CMP-NEU,EMP-NEU], [DIS], [MAJ]]\n "