{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOMAIN_SPECIFIC_L4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFdBV4qGvSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pre\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "label=label=pre.create_label(1)\n",
        "corpus=pre.create_sentence_list(0)\n",
        "\n",
        "fileid=pre.fileid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyhnG0zHDBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_label=[]\n",
        "new_tv=[]\n",
        "new_fileid=[]\n",
        "new_corpus=[]\n",
        "length = len(corpus)\n",
        "for i in range(0, length):\n",
        "  for j in range(0,len(label[i])):\n",
        "    new_corpus.append(corpus[i])\n",
        "    new_label.append(label[i][j])\n",
        "    new_fileid.append(fileid[i])\n",
        "# df=pre.pd.DataFrame(pre.np.round(new_tv, 10), columns=vocab)\n",
        "# #df_tfidf.insert(0, \"sentences\", corpus)\n",
        "# df_tfidf[\"tag\"]=new_label\n",
        "# df_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZZSiCt9vRQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nltk.download('maxent_ne_chunker')\n",
        "\n",
        "sentences=new_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz3jyLDUvoqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk import ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy \n",
        "from collections import Counter\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "\n",
        "verb_count=[]\n",
        "noun_count=[]\n",
        "adjective_count=[]\n",
        "cardinal_count=[]\n",
        "is_date=[]\n",
        "adverb_count=[]\n",
        "for sent in sentences:\n",
        "  text= pos_tag(word_tokenize(sent))\n",
        "  count= Counter([j for i,j in pos_tag(word_tokenize(sent))])\n",
        "  noun_count.append(count['NN']+count['NNS']+count['NNP']+count['NNPS'])\n",
        "  verb_count.append(count['VBZ']+count['VB']+count['VBD']+count['VBG']+count['VBN']+count['VBP'])\n",
        "  adjective_count.append(count['JJ']+count['JJR']+count['JJS'])\n",
        "  cardinal_count.append(count['CD'])\n",
        "  adverb_count.append(count['RB']+count['RBR']+count['RBS'])\n",
        "\n",
        "\n",
        "  doc = nlp(sent)\n",
        "  ner_labels= ([X.label_ for X in doc.ents])\n",
        "  if 'DATE' in ner_labels:\n",
        "    is_date.append(1)\n",
        "  else:\n",
        "    is_date.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkfAG4PNAx1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_count(str):\n",
        "    counts = dict()\n",
        "    words = str.split()\n",
        "\n",
        "    for word in words:\n",
        "        if word in counts:\n",
        "            counts[word] += 1\n",
        "        else:\n",
        "            counts[word] = 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "print( word_count('the quick brown fox jumps over the lazy dog.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQiPKuXKnISs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mathematical_terms= ['Addition', 'Add', 'Sum', 'Plus', 'Increase', 'Total',\n",
        "'Subtraction', 'Subtract', 'Minus', 'Less', 'Difference', 'Decrease', 'Deduct'\n",
        ",'Multiplication', 'Multiply',' Product', 'By', 'Times','Division', 'Divide', 'Quotient','variables']\n",
        "\n",
        "question_word=['which', 'what','whose','who', 'whom', 'whose','what', 'which','where','whither' ,'whence' ,'when','how','why','whether']\n",
        "\n",
        "abs_terms = ['Interesting','stronger','well','written','novelty','quite','organized','clear','accept']\n",
        "intro_terms=['not clear', 'missing','seems', 'quite','limited','lacking','but']\n",
        "rel_wrk=['discusses', 'problem', 'present']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHU292uMgAn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "math_count=[]\n",
        "ques_wcount=[]\n",
        "f1=[]\n",
        "f2=[]\n",
        "f3=[]\n",
        "\n",
        "\n",
        "for sent in sentences:\n",
        "  dic= word_count(sent)\n",
        "\n",
        "  count=0     #mathematical\n",
        "  for word in mathematical_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  math_count.append(count)\n",
        "\n",
        "  count=0     #question word\n",
        "  for word in question_word:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  ques_wcount.append(count)\n",
        "\n",
        "  count=0     #ABS word\n",
        "  for word in abs_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f1.append(count)\n",
        "\n",
        "  count=0     #INTRO word\n",
        "  for word in intro_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f2.append(count)\n",
        "\n",
        "  count=0     #REL word\n",
        "  for word in rel_wrk:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f3.append(count)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR-VUMNUgLv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def punctuation(str,p):\n",
        "  count = 0; \n",
        "  for i in range (0, len (str)):   \n",
        "      #Checks whether given character is a punctuation mark  \n",
        "      if str[i] in (p):  \n",
        "          count = count + 1;  \n",
        "  return count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qRCewJuo32x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_qmark=[]\n",
        "num_excla=[]\n",
        "num_per=[]\n",
        "et_al=[]\n",
        "for sent in sentences:\n",
        "  num_qmark.append(punctuation(sent,'?'))\n",
        "  num_excla.append(punctuation(sent,'!'))\n",
        "  num_per.append(punctuation(sent,'%'))\n",
        "  et_al.append(punctuation(sent,'et al'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J7zWdWzcuqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_len=[]\n",
        "for sent in sentences:\n",
        "  count=0\n",
        "  words= word_tokenize(sent)\n",
        "  for word in words:\n",
        "    count=count+len(word)\n",
        "  if(len(words)!=0):\n",
        "    avg_len.append(count/len(words))\n",
        "  else:\n",
        "    avg_len.append(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KAzc5HyhTJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic={'verb':verb_count,'noun':noun_count,'adj':adjective_count,'qmark':num_qmark,'excla':num_excla,'%':num_per,'number':cardinal_count,'date':is_date,'adverb':adverb_count,\\\n",
        "     'math':math_count,'ques':ques_wcount,'avg_len':avg_len,'f1':f1,'f2':f2,'f3':f3}\n",
        "df=pre.pd.DataFrame(dic)\n",
        "df['tag']=new_label\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qREbw8OPycaE",
        "colab_type": "text"
      },
      "source": [
        "CREATE X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a04GT2iKm4mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_df=df[df.columns[0:-1]] #X dataframe\n",
        "X=X_df.to_numpy()    # X in array\n",
        "y=df[\"tag\"]\n",
        "print(np.unique(df[\"tag\"]))\n",
        "class_names=np.unique(df[\"tag\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jtsqQ_yfWm",
        "colab_type": "text"
      },
      "source": [
        "SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcsCHHisybnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
        "y_tr=y_tr.reset_index()['tag'].tolist()\n",
        "print(X_tr.shape)\n",
        "print(len(y_tr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVzyGuxbRiFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_tr\n",
        "y_train=y_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk-Bpk_SyjOY",
        "colab_type": "text"
      },
      "source": [
        "FITTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEEHCtTl0ISo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape)\n",
        "len(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik51MiH1ys0K",
        "colab_type": "text"
      },
      "source": [
        "LOGISTIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN8_qh9nymlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "logmodel = LogisticRegression(class_weight='balanced',solver='liblinear')\n",
        "logmodel.fit(X_train,y_train)\n",
        "y_pred = logmodel.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJnpvsj8y5jg",
        "colab_type": "text"
      },
      "source": [
        "MULTINOMIAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI9sMxUMy7T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fPeqGRGy-Sk",
        "colab_type": "text"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfrKxHJgy_q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                               bootstrap = True,\n",
        "                               max_features = 'sqrt',class_weight='balanced_subsample')\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdbkCZM4zDoc",
        "colab_type": "text"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOwpth8XzEXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Make a decision tree and train\n",
        "clf = svm.SVC(class_weight='balanced',decision_function_shape='ovo')\n",
        "import sklearn.metrics as metrics\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUVPTgIhzKa9",
        "colab_type": "text"
      },
      "source": [
        "SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcvbBNGNzLDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMuRp6lqzOx8",
        "colab_type": "text"
      },
      "source": [
        "DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhv_RuNPzP_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}