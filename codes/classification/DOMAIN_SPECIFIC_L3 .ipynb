{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOMAIN_SPECIFIC_L3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFdBV4qGvSV",
        "outputId": "b6b97ec3-9018-4261-c0b5-ba4935df88d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import pre\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "label=label=pre.create_label(0) \n",
        "corpus=pre.create_sentence_list(0)\n",
        "\n",
        "fileid=pre.fileid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyhnG0zHDBq"
      },
      "source": [
        "new_label=[]\n",
        "new_tv=[]\n",
        "new_fileid=[]\n",
        "new_corpus=[]\n",
        "length = len(corpus)\n",
        "for i in range(0, length):\n",
        "  for j in range(0,len(label[i])):\n",
        "    new_corpus.append(corpus[i])\n",
        "    new_label.append(label[i][j])\n",
        "    new_fileid.append(fileid[i])\n",
        "# df=pre.pd.DataFrame(pre.np.round(new_tv, 10), columns=vocab)\n",
        "# #df_tfidf.insert(0, \"sentences\", corpus)\n",
        "# df_tfidf[\"tag\"]=new_label\n",
        "# df_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZZSiCt9vRQw",
        "outputId": "02cb5e0c-40ec-481d-f3d2-84c49206ffe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!nltk.download('maxent_ne_chunker')\n",
        "\n",
        "sentences=new_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `'maxent_ne_chunker''\n",
            "/bin/bash: -c: line 0: `nltk.download('maxent_ne_chunker')'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz3jyLDUvoqJ"
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "from nltk import ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy \n",
        "from collections import Counter\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "\n",
        "verb_count=[]\n",
        "noun_count=[]\n",
        "adjective_count=[]\n",
        "cardinal_count=[]\n",
        "is_date=[]\n",
        "adverb_count=[]\n",
        "for sent in sentences:\n",
        "  text= pos_tag(word_tokenize(sent))\n",
        "  count= Counter([j for i,j in pos_tag(word_tokenize(sent))])\n",
        "  noun_count.append(count['NN']+count['NNS']+count['NNP']+count['NNPS'])\n",
        "  verb_count.append(count['VBZ']+count['VB']+count['VBD']+count['VBG']+count['VBN']+count['VBP'])\n",
        "  adjective_count.append(count['JJ']+count['JJR']+count['JJS'])\n",
        "  cardinal_count.append(count['CD'])\n",
        "  adverb_count.append(count['RB']+count['RBR']+count['RBS'])\n",
        "\n",
        "\n",
        "  doc = nlp(sent)\n",
        "  ner_labels= ([X.label_ for X in doc.ents])\n",
        "  if 'DATE' in ner_labels:\n",
        "    is_date.append(1)\n",
        "  else:\n",
        "    is_date.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkfAG4PNAx1d",
        "outputId": "9a2ce726-87b1-452b-fef3-a288a090ab09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def word_count(str):\n",
        "    counts = dict()\n",
        "    words = str.split()\n",
        "\n",
        "    for word in words:\n",
        "        if word in counts:\n",
        "            counts[word] += 1\n",
        "        else:\n",
        "            counts[word] = 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "print( word_count('the quick brown fox jumps over the lazy dog.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 2, 'quick': 1, 'brown': 1, 'fox': 1, 'jumps': 1, 'over': 1, 'lazy': 1, 'dog.': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQiPKuXKnISs"
      },
      "source": [
        "mathematical_terms= ['Addition', 'Add', 'Sum', 'Plus', 'Increase', 'Total',\n",
        "'Subtraction', 'Subtract', 'Minus', 'Less', 'Difference', 'Decrease', 'Deduct'\n",
        ",'Multiplication', 'Multiply',' Product', 'By', 'Times','Division', 'Divide', 'Quotient','variables']\n",
        "\n",
        "question_word=['which', 'what','whose','who', 'whom', 'whose','what', 'which','where','whither' ,'whence' ,'when','how','why','whether']\n",
        "\n",
        "abs_terms = ['proposes','Summary'] \n",
        "intro_terms=['might', 'may','consider', 'if', 'can']\n",
        "rel_wrk=['interesting','stronger','well', 'written','novel','clear','nicely']\n",
        "pdi=['interesting','stronger','well', 'written','novel','clear','nicely']\n",
        "dataset=['should','seems','could','Would']\n",
        "meth=['confusing','not', 'novel']\n",
        "exp_terms=['accept', 'reject']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHU292uMgAn8"
      },
      "source": [
        "math_count=[]\n",
        "ques_wcount=[]\n",
        "f1=[]\n",
        "f2=[]\n",
        "f3=[]\n",
        "f4=[]\n",
        "f5=[]\n",
        "f6=[]\n",
        "f7=[]\n",
        "\n",
        "for sent in sentences:\n",
        "  dic= word_count(sent)\n",
        "\n",
        "  count=0     #mathematical\n",
        "  for word in mathematical_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  math_count.append(count)\n",
        "\n",
        "  count=0     #question word\n",
        "  for word in question_word:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  ques_wcount.append(count)\n",
        "\n",
        "  count=0     \n",
        "  for word in abs_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f1.append(count)\n",
        "\n",
        "  count=0     \n",
        "  for word in intro_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f2.append(count)\n",
        "\n",
        "  count=0     \n",
        "  for word in rel_wrk:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f3.append(count)\n",
        "\n",
        "  count=0     #PDI word\n",
        "  for word in pdi:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f4.append(count)\n",
        "\n",
        "  count=0     #question word\n",
        "  for word in dataset:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f5.append(count)\n",
        "\n",
        "  count=0     #meth word\n",
        "  for word in meth:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f6.append(count)\n",
        "\n",
        "  count=0     #EXP word\n",
        "  for word in exp_terms:\n",
        "    word=word.lower()\n",
        "    if word in dic.keys():\n",
        "      count=count+dic[word]\n",
        "  f7.append(count)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR-VUMNUgLv9"
      },
      "source": [
        "def punctuation(str,p):\n",
        "  count = 0; \n",
        "  for i in range (0, len (str)):   \n",
        "      #Checks whether given character is a punctuation mark  \n",
        "      if str[i] in (p):  \n",
        "          count = count + 1;  \n",
        "  return count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qRCewJuo32x"
      },
      "source": [
        "num_qmark=[]\n",
        "num_excla=[]\n",
        "num_per=[]\n",
        "et_al=[]\n",
        "for sent in sentences:\n",
        "  num_qmark.append(punctuation(sent,'?'))\n",
        "  num_excla.append(punctuation(sent,'!'))\n",
        "  num_per.append(punctuation(sent,'%'))\n",
        "  et_al.append(punctuation(sent,'et al'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J7zWdWzcuqQ"
      },
      "source": [
        "avg_len=[]\n",
        "for sent in sentences:\n",
        "  count=0\n",
        "  words= word_tokenize(sent)\n",
        "  for word in words:\n",
        "    count=count+len(word)\n",
        "  if(len(words)!=0):\n",
        "    avg_len.append(count/len(words))\n",
        "  else:\n",
        "    avg_len.append(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KAzc5HyhTJM",
        "outputId": "543cb976-d0c0-4389-83e4-c8864293a06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "dic={'verb':verb_count,'noun':noun_count,'adj':adjective_count,'qmark':num_qmark,'excla':num_excla,'%':num_per,'number':cardinal_count,'date':is_date,'adverb':adverb_count,\\\n",
        "     'math':math_count,'ques':ques_wcount,'avg_len':avg_len,'f1':f1,'f2':f2,'f3':f3,'f4':f4,'f5':f5,'f6':f6,'f7':f7}\n",
        "df=pre.pd.DataFrame(dic)\n",
        "df['tag']=new_label\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verb</th>\n",
              "      <th>noun</th>\n",
              "      <th>adj</th>\n",
              "      <th>qmark</th>\n",
              "      <th>excla</th>\n",
              "      <th>%</th>\n",
              "      <th>number</th>\n",
              "      <th>date</th>\n",
              "      <th>adverb</th>\n",
              "      <th>math</th>\n",
              "      <th>ques</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.607143</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SMY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SMY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.444444</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>CRT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.785714</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>CRT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.434783</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16894</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.782609</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>SUG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16895</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.120000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>APC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16896</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>APC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16897</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>APC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16898</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>CRT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16899 rows Ã— 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       verb  noun  adj  qmark  excla  %  number  ...  f2  f3  f4  f5  f6  f7  tag\n",
              "0         2     7    4      0      0  0       0  ...   1   0   0   0   0   0  SMY\n",
              "1         3     9    2      0      0  0       0  ...   0   0   0   0   0   0  SMY\n",
              "2         1     2    2      0      0  0       0  ...   0   0   0   0   0   0  CRT\n",
              "3         3     3    1      0      0  0       0  ...   0   0   0   0   0   0  CRT\n",
              "4         4     7    2      0      0  0       0  ...   0   0   0   0   0   0  DIS\n",
              "...     ...   ...  ...    ...    ... ..     ...  ...  ..  ..  ..  ..  ..  ..  ...\n",
              "16894     4     5    2      0      0  0       0  ...   1   1   1   0   0   0  SUG\n",
              "16895     5     9    3      0      0  0       0  ...   0   1   1   0   0   0  APC\n",
              "16896     2     3    2      0      0  0       0  ...   0   0   0   0   0   0  APC\n",
              "16897     3     1    0      0      0  0       0  ...   0   1   1   0   0   0  APC\n",
              "16898     4     4    3      0      0  0       1  ...   1   0   0   0   0   0  CRT\n",
              "\n",
              "[16899 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qREbw8OPycaE"
      },
      "source": [
        "CREATE X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a04GT2iKm4mQ",
        "outputId": "65b54abd-e19d-4fe9-f67d-6bd32c8bd6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "X_df=df[df.columns[0:-1]] #X dataframe\n",
        "X=X_df.to_numpy()    # X in array\n",
        "y=df[\"tag\"]\n",
        "print(np.unique(df[\"tag\"]))\n",
        "class_names=np.unique(df[\"tag\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['APC' 'CNT' 'CRT' 'DFT' 'DIS' 'FBK' 'QSN' 'SMY' 'SUG']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jtsqQ_yfWm"
      },
      "source": [
        "SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcsCHHisybnz",
        "outputId": "d63e7dc5-4ba8-45ca-d8d2-fcd26507e1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
        "y_tr=y_tr.reset_index()['tag'].tolist()\n",
        "print(X_tr.shape)\n",
        "print(len(y_tr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11322, 19)\n",
            "11322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk-Bpk_SyjOY"
      },
      "source": [
        "FITTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Pe05dfH_wl"
      },
      "source": [
        "X_train=X_tr\n",
        "y_train=y_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf8bOglRII_y",
        "outputId": "cc04529d-b92f-4e2b-edc9-80c79d0eb085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11322, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik51MiH1ys0K"
      },
      "source": [
        "LOGISTIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN8_qh9nymlD",
        "outputId": "5ff93597-7634-4f06-b92c-f8bbcdd83a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "logmodel = LogisticRegression(class_weight='balanced',solver='liblinear')\n",
        "logmodel.fit(X_train,y_train)\n",
        "y_pred = logmodel.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.38      0.39      0.39       818\n",
            "         CNT       0.01      0.30      0.01        10\n",
            "         CRT       0.46      0.40      0.42      1115\n",
            "         DFT       0.09      0.00      0.00       514\n",
            "         DIS       0.33      0.09      0.14       919\n",
            "         FBK       0.05      0.14      0.08        96\n",
            "         QSN       0.83      0.87      0.85       555\n",
            "         SMY       0.43      0.53      0.47      1108\n",
            "         SUG       0.29      0.50      0.37       442\n",
            "\n",
            "    accuracy                           0.39      5577\n",
            "   macro avg       0.32      0.36      0.30      5577\n",
            "weighted avg       0.40      0.39      0.37      5577\n",
            "\n",
            "Accuracy: 0.3864084633315403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJnpvsj8y5jg"
      },
      "source": [
        "MULTINOMIAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI9sMxUMy7T4",
        "outputId": "38d097c7-1a03-4f3e-f9e9-e3a74ccdf591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.46      0.37      0.41       818\n",
            "         CNT       0.00      0.00      0.00        10\n",
            "         CRT       0.43      0.48      0.45      1115\n",
            "         DFT       0.00      0.00      0.00       514\n",
            "         DIS       0.29      0.16      0.21       919\n",
            "         FBK       0.33      0.02      0.04        96\n",
            "         QSN       0.75      0.83      0.79       555\n",
            "         SMY       0.37      0.70      0.49      1108\n",
            "         SUG       0.32      0.31      0.32       442\n",
            "\n",
            "    accuracy                           0.42      5577\n",
            "   macro avg       0.33      0.32      0.30      5577\n",
            "weighted avg       0.38      0.42      0.39      5577\n",
            "\n",
            "Accuracy: 0.42442173211403983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fPeqGRGy-Sk"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfrKxHJgy_q4",
        "outputId": "3a9fd49e-5478-4ca0-b7ec-c27c589ea05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                               bootstrap = True,\n",
        "                               max_features = 'sqrt',class_weight='balanced_subsample')\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.38      0.37      0.38       818\n",
            "         CNT       1.00      0.00      0.00        10\n",
            "         CRT       0.38      0.46      0.41      1115\n",
            "         DFT       0.10      0.04      0.06       514\n",
            "         DIS       0.25      0.17      0.20       919\n",
            "         FBK       0.03      0.01      0.02        96\n",
            "         QSN       0.81      0.87      0.84       555\n",
            "         SMY       0.42      0.53      0.47      1108\n",
            "         SUG       0.28      0.36      0.31       442\n",
            "\n",
            "    accuracy                           0.40      5577\n",
            "   macro avg       0.41      0.31      0.30      5577\n",
            "weighted avg       0.37      0.40      0.38      5577\n",
            "\n",
            "Accuracy: 0.3991393222162453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdbkCZM4zDoc"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOwpth8XzEXB",
        "outputId": "381d18b6-0b85-42fe-d240-8a8607a33c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Make a decision tree and train\n",
        "clf = svm.SVC(class_weight='balanced',decision_function_shape='ovo')\n",
        "import sklearn.metrics as metrics\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.51      0.28      0.36       818\n",
            "         CNT       0.00      0.20      0.01        10\n",
            "         CRT       0.47      0.25      0.33      1115\n",
            "         DFT       0.19      0.04      0.07       514\n",
            "         DIS       0.28      0.13      0.18       919\n",
            "         FBK       0.05      0.34      0.08        96\n",
            "         QSN       0.83      0.86      0.85       555\n",
            "         SMY       0.44      0.54      0.49      1108\n",
            "         SUG       0.28      0.52      0.36       442\n",
            "\n",
            "    accuracy                           0.36      5577\n",
            "   macro avg       0.34      0.35      0.30      5577\n",
            "weighted avg       0.43      0.36      0.36      5577\n",
            "\n",
            "Accuracy: 0.35700197238658776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUVPTgIhzKa9"
      },
      "source": [
        "SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcvbBNGNzLDS",
        "outputId": "e6c3fcb4-34ff-489d-b617-ba8dc4cca44c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.62      0.09      0.15       818\n",
            "         CNT       0.00      0.00      0.00        10\n",
            "         CRT       0.27      0.82      0.40      1115\n",
            "         DFT       0.00      0.00      0.00       514\n",
            "         DIS       0.27      0.07      0.11       919\n",
            "         FBK       0.20      0.01      0.02        96\n",
            "         QSN       0.85      0.74      0.79       555\n",
            "         SMY       0.50      0.36      0.42      1108\n",
            "         SUG       0.31      0.34      0.32       442\n",
            "\n",
            "    accuracy                           0.36      5577\n",
            "   macro avg       0.33      0.27      0.25      5577\n",
            "weighted avg       0.40      0.36      0.31      5577\n",
            "\n",
            "Accuracy: 0.3609467455621302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMuRp6lqzOx8"
      },
      "source": [
        "DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhv_RuNPzP_N",
        "outputId": "48cc4e69-6b20-417e-bcfa-49c194efc20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred,zero_division=1))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         APC       0.32      0.36      0.34       818\n",
            "         CNT       0.00      0.00      0.00        10\n",
            "         CRT       0.29      0.30      0.29      1115\n",
            "         DFT       0.11      0.10      0.11       514\n",
            "         DIS       0.21      0.20      0.21       919\n",
            "         FBK       0.04      0.04      0.04        96\n",
            "         QSN       0.73      0.74      0.73       555\n",
            "         SMY       0.38      0.37      0.38      1108\n",
            "         SUG       0.20      0.20      0.20       442\n",
            "\n",
            "    accuracy                           0.32      5577\n",
            "   macro avg       0.25      0.26      0.26      5577\n",
            "weighted avg       0.32      0.32      0.32      5577\n",
            "\n",
            "Accuracy: 0.3179128563743948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pENL1e7G_H4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}