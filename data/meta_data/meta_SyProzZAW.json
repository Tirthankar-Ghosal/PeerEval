{"title": "ICLR 2018 Conference Acceptance Decision", "comment": "All the reviewers are agree on the significance of the topic of understanding expressivity of deep networks. This paper makes good progress in analyzing the ability of deep networks to fit multivariate polynomials. They show exponential depth advantage for general sparse polynomials.\n\n I am very surprised that the paper misses the original contribution of Andrew Barron. He analyzes the size of the shallow neural networks needed to fit a wide class of functions including polynomials. The deep learning community likes to think that everything has been invented in the current decade.\n\n@article{barron1994approximation,\n  title={Approximation and estimation bounds for artificial neural networks},\n  author={Barron, Andrew R},\n  journal={Machine Learning},\n  volume={14},\n  number={1},\n  pages={115--133},\n  year={1994},\n  publisher={Springer}\n}", "decision": "Accept (Poster)"}