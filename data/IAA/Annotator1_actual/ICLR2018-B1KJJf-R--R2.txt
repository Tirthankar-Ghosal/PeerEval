"This paper tackles the problem of doing program synthesis when given a problem description and a small number of input-output examples. The approach is to use a sequence-to-tree model along with an adaptation of beam search for generating tree-structured outputs. In addition, the paper assembles a template-based synthetic dataset of task descriptions and programs.  Results show that a Seq2Tree model outperforms a Seq2Seq model, that adding search to Seq2Tree improves results, and that search without any training performs worse, although the experiments assume that only a fixed number of programs are explored at test time regardless of the wall time that it takes a technique.\n\nStrengths:\n\n- Reasonable approach, quality is good\n\n- The DSL is richer than that of previous related work like Balog et al. (2016).\n\n- Results show a reasonable improvement in using a Seq2Tree model over a Seq2Seq model, which is interesting.\n\nWeaknesses:\n\n- There are now several papers on using a trained neural network to guide search, and this approach doesn't add too much on top of previous work. Using beam search on tree outputs is a bit of a minor contribution.\n\n- The baselines are just minor variants of the proposed method. It would be stronger to compare against a range of different approaches to the problem, particularly given that the paper is working with a new dataset.\n\n- Data is synthetic, and it's hard to get a sense for how difficult the presented problem is, as there are just four example problems given.\n\nQuestions:\n\n- Why not compare against Seq2Seq + Search?\n\n- How about comparing wall time against a traditional program synthesis technique (i.e., no machine learning), ignoring the descriptions. I would guess that an efficiently-implemented enumerative search technique could quickly explore all programs of depth 3, which makes me skeptical that Figure 4 is a fair representation of how well a non neural network-based search could do.\n\n- Are there plans to release the dataset? Could you provide a large sample of the data at an anonymized link? I'd re-evaluate my rating after looking at the data in more detail.\n"